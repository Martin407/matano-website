"use strict";(self.webpackChunk_matano_website=self.webpackChunk_matano_website||[]).push([[4609],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>d});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,l=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),m=u(n),d=o,g=m["".concat(s,".").concat(d)]||m[d]||p[d]||l;return n?a.createElement(g,r(r({ref:t},c),{},{components:n})):a.createElement(g,r({ref:t},c))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var l=n.length,r=new Array(l);r[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:o,r[1]=i;for(var u=2;u<l;u++)r[u]=n[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},6986:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>p,frontMatter:()=>l,metadata:()=>i,toc:()=>u});var a=n(7462),o=(n(7294),n(3905));const l={title:"Log source configuration",sidebar_position:4},r=void 0,i={unversionedId:"log-sources/configuration",id:"log-sources/configuration",title:"Log source configuration",description:"Configuring log sources",source:"@site/docs/log-sources/configuration.md",sourceDirName:"log-sources",slug:"/log-sources/configuration",permalink:"/docs/log-sources/configuration",draft:!1,editUrl:"https://github.com/matanolabs/matano-website/tree/main/website/docs/log-sources/configuration.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Log source configuration",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Transformation",permalink:"/docs/log-sources/transformation"},next:{title:"Log source schema",permalink:"/docs/log-sources/schema"}},s={},u=[{value:"Configuring log sources",id:"configuring-log-sources",level:2},{value:"Log source configuration file",id:"log-source-configuration-file",level:3},{value:"Fields",id:"fields",level:4},{value:"Creating multiple tables from a log source",id:"creating-multiple-tables-from-a-log-source",level:2},{value:"Table configuration file",id:"table-configuration-file",level:3},{value:"Shared log configuration fields",id:"shared-log-configuration-fields",level:4},{value:"Table selection",id:"table-selection",level:3},{value:"Selecting table from payload metadata",id:"selecting-table-from-payload-metadata",level:4},{value:"Selecting table from payload data",id:"selecting-table-from-payload-data",level:4}],c={toc:u};function p(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"configuring-log-sources"},"Configuring log sources"),(0,o.kt)("p",null,"To create a log source, create a directory under the ",(0,o.kt)("inlineCode",{parentName:"p"},"log_sources")," subdirectory in your Matano directory and create a file named ",(0,o.kt)("inlineCode",{parentName:"p"},"log_source.yml"),". The directory structure is as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"my-matano-dir/\n\u2514\u2500\u2500 log_sources/\n    \u2514\u2500\u2500 aws_cloudtrail/\n        \u2514\u2500\u2500 log_source.yml\n")),(0,o.kt)("h3",{id:"log-source-configuration-file"},"Log source configuration file"),(0,o.kt)("p",null,"The configuration for a log source lives in a YAML file named ",(0,o.kt)("inlineCode",{parentName:"p"},"log_source.yml"),". The file has the following fields."),(0,o.kt)("h4",{id:"fields"},"Fields"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yml"},'# The unique name of the log source.\nname: "my_log_source"\n\n# Optional: Properties for managed log sources\nmanaged:\n  # The identifier of the managed log source\n  type: "MY_LOG_SOURCE"\n  # Map of string values for managed log source configuration\n  properties: {}\n\n# Optional\ningest:\n  # Custom: Optionally bring your own bucket\n  s3_source:\n    # Name of existing S3 Bucket to use as a source\n    bucket_name: "my-bucket"\n    # Object key prefix for existing S3 source\n    key_prefix: "my-prefix"\n\n  # Custom: (Multi table log sources only) Used for mapping incoming data to the appropriate table at runtime based on file object metadata\n  select_table_from_payload_metadata: |\n    if match(.__metadata.s3.key, r\'somepath\') { "other_table" } else { "main_table" }\n  # Custom: (Multi table log sources only) Used for mapping incoming data to the appropriate table at runtime dynamically based on the content of the event\n  select_table_from_payload: |\n    if ._table_name == "audit" {\n      "audits"\n    } else {\n      "main"\n    }\n\n# Defines the schema for a log source.\n# Note: For managed log sources, this will only extend the pre-defined schema with additional fields.\nschema:\n  ecs_field_names:\n    - event\n    # use dotted path to select nested fields\n    - user.id\n  # List of custom schema fields in Apache Iceberg format.\n  fields:\n    - name: aws\n      type:\n        type: struct\n        fields: []\n\n# The VRL program to transform your data.\n# Note: For managed log sources, this will extend the pre-defined transformations and run afterwards allowing you to perform any additional custom transformations.\ntransform: |\n  if .json.eventTime != null {\n      .ts = to_timestamp!(.json.eventTime, "milliseconds")\n  }\n')),(0,o.kt)("h2",{id:"creating-multiple-tables-from-a-log-source"},"Creating multiple tables from a log source"),(0,o.kt)("p",null,"By default, a log source will generate a single table with the same name as the log source."),(0,o.kt)("p",null,"Matano supports creating multiple Matano tables from a single log source."),(0,o.kt)("p",null,"To configure multiple tables from a log source, create a ",(0,o.kt)("inlineCode",{parentName:"p"},"tables/")," subdirectory in your log source directory. For example, if you have the log source ",(0,o.kt)("inlineCode",{parentName:"p"},"aws_cloudtrail"),", your directory structure would be as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"my-matano-dir/\n\u2514\u2500\u2500 log_sources/\n    \u2514\u2500\u2500 aws_cloudtrail/\n        \u2514\u2500\u2500 log_source.yml\n        \u2514\u2500\u2500 tables/\n            \u251c\u2500\u2500 default.yml\n            \u2514\u2500\u2500 digest.yml\n")),(0,o.kt)("p",null,"The files named ",(0,o.kt)("inlineCode",{parentName:"p"},"default.yml")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"digest.yml")," are ",(0,o.kt)("em",{parentName:"p"},"table configuration files"),"."),(0,o.kt)("h3",{id:"table-configuration-file"},"Table configuration file"),(0,o.kt)("p",null,"The table configuration file is a YAML file with the following structure:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yml"},'# optional, if omitted will use the log source name\nname: "dns"\n\n# optional, same as in `log_source.yml`\n# will be merged with schema in `log_source.yml`\nschema:\n  fields:\n    - name: custom_field\n      type: string\n\n# optional, same as in `log_source.yml\n# will be merged with schema in `log_source.yml`\ntransform: |\n  if .ts != null {\n      .event.created = .ts\n  }\n')),(0,o.kt)("h4",{id:"shared-log-configuration-fields"},"Shared log configuration fields"),(0,o.kt)("p",null,"Table level configurations 'inherit' from log source level configurations defined in the corresponding ",(0,o.kt)("inlineCode",{parentName:"p"},"log_source.yml")," and both log source level and table level configurations will be merged. You can use this to share properties and logic common to all tables within a log source while applying custom properties to each table."),(0,o.kt)("p",null,"The name defined in a table configuration will be combined with the log source name to form the final Matano table name. For example, a log source named ",(0,o.kt)("inlineCode",{parentName:"p"},"zeek")," with a table ",(0,o.kt)("inlineCode",{parentName:"p"},"dns")," will result in a Matano table named ",(0,o.kt)("inlineCode",{parentName:"p"},"zeek_dns"),"."),(0,o.kt)("h3",{id:"table-selection"},"Table selection"),(0,o.kt)("p",null,"When Matano ingests data for a log source with multiple tables, it will route the data to the correct table based on the incoming data's metadata. Matano supports dynamic selection of the table to route an incoming payload to using a VRL expression that Matano evaluates on either the metadata of the incoming payload or on the actual payload data."),(0,o.kt)("h4",{id:"selecting-table-from-payload-metadata"},"Selecting table from payload metadata"),(0,o.kt)("p",null,"You can select the table for a log source with multiple tables based on the incoming payload metadata such as the S3 bucket and key."),(0,o.kt)("p",null,"To define the table selection VRL expression use the ",(0,o.kt)("inlineCode",{parentName:"p"},"ingest.select_table_from_payload_metadata")," key in your ",(0,o.kt)("strong",{parentName:"p"},"log_source.yml"),"."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Expression input")),(0,o.kt)("p",null,"Your VRL expression is passed a ",(0,o.kt)("inlineCode",{parentName:"p"},"__metadata")," key with the following structure:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "__metadata": {\n    "s3": {\n      "bucket": "my-bucket",\n      "key": "my/key",\n      "size": 123456 // integer bytes\n    }\n  }\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Expression output")),(0,o.kt)("p",null,"The expression should return a string containing the table name that the data maps to."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Example of selecting table from payload metadata")),(0,o.kt)("p",null,"For example, the ",(0,o.kt)("inlineCode",{parentName:"p"},"aws_cloudtrail")," log source has 3 tables configured. The following VRL expression is defined to select the appropriate table from the uploaded file:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yml"},'# log_source.yml\n\nselect_table_from_payload_metadata: |\n  if match(.__metadata.s3.key, r\'Digest\') {\n    "digest"\n  } else if match(.__metadata.s3.key, r\'Insights\') {\n    "insights"\n  } else {\n    "default"\n  }\n')),(0,o.kt)("h4",{id:"selecting-table-from-payload-data"},"Selecting table from payload data"),(0,o.kt)("p",null,"You can select the table for a log source with multiple tables based on the content of the event data."),(0,o.kt)("p",null,"To define the table selection VRL expression use the ",(0,o.kt)("inlineCode",{parentName:"p"},"ingest.select_table_from_payload")," key in your ",(0,o.kt)("strong",{parentName:"p"},"log_source.yml"),"."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Expression input")),(0,o.kt)("p",null,"Your VRL expression for selecting the table from the payload is passed the same input as for your transformer script: The event is accessible under the ",(0,o.kt)("inlineCode",{parentName:"p"},".json")," property if it is json and ",(0,o.kt)("inlineCode",{parentName:"p"},".message")," if it is not."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Expression output")),(0,o.kt)("p",null,"The expression should return a string containing the table name that the data maps to."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Example of selecting table from payload data")),(0,o.kt)("p",null,"For example, the ",(0,o.kt)("inlineCode",{parentName:"p"},"microsoft_aad")," log source has 2 tables configured. The following VRL expression is defined to select the appropriate table from the uploaded file based on a property inside the event data:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yml"},'# log_source.yml\n\nselect_table_from_payload: |\n  if .json.table_name == "audit" {\n    "audits"\n  } else if json.table_name == "signin" {\n    "signin"\n  } else {\n    abort\n  }\n')))}p.isMDXComponent=!0}}]);